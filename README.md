# RAG Chroma Gemini App

A powerful PDF Chat Assistant that combines Retrieval-Augmented Generation (RAG) with Google's Gemini AI for intelligent document processing and conversational querying.

## ğŸš€ Features

- **ğŸ“„ PDF Text Extraction**: Advanced text extraction from PDF documents using Google's Gemini 2.5 Flash model
- **ğŸ§  Intelligent Chat**: Conversational AI powered by Gemini 2.5 Flash for answering questions about your documents
- **ğŸ’¾ Vector Storage**: Persistent document storage using ChromaDB with MPNet embeddings
- **ğŸ” Semantic Search**: Efficient retrieval of relevant document chunks using vector similarity
- **ğŸ’¬ Streamlit Interface**: Modern, responsive web interface for easy interaction
- **ğŸ“ Multi-Document Support**: Process and chat with multiple PDF files simultaneously
- **ğŸ’¾ Text File Export**: Automatically saves extracted text as .txt files for future reference

## ğŸ› ï¸ Technology Stack

- **Frontend**: [Streamlit](https://streamlit.io/)
- **AI Models**:
  - [Google Gemini 2.5 Flash](https://ai.google.dev/models/gemini) (for both text extraction and chat)
  - [Sentence Transformers MPNet](https://huggingface.co/sentence-transformers/all-mpnet-base-v2) (for embeddings)
- **Vector Database**: [ChromaDB](https://www.trychroma.com/)
- **Embeddings**: [HuggingFace Transformers](https://huggingface.co/docs/transformers/index)
- **RAG Framework**: [LangChain](https://www.langchain.com/)
- **PDF Processing**: [PyPDF2](https://pypdf2.readthedocs.io/) + Gemini AI

## ğŸ“‹ Prerequisites

- Python 3.10 or higher
- Google Gemini API key (get one from [Google AI Studio](https://makersuite.google.com/app/apikey))

## ğŸ”§ Installation


1. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

2. **Set up environment variables**:
   - Copy `.env.example` to `.env` (if exists) or create a `.env` file
   - Add your Google Gemini API key:
     ```
     GOOGLE_API_KEY=your_api_key_here
     ```

## ğŸš€ Usage

1. **Run the application**:
   ```bash
   streamlit run app.py
   ```

2. **Access the app**:
   - Open your browser and go to `http://localhost:8501`

3. **Upload PDFs**:
   - Use the sidebar to upload one or more PDF files
   - Click "ğŸš€ Process with Gemini & Extract Text" to process documents

4. **Start chatting**:
   - Ask questions about your uploaded documents in the chat interface
   - The AI will provide answers based on the content of your PDFs

## ğŸ“ Project Structure

```
rag-chroma-gemini-app/
â”œâ”€â”€ app.py                 # Main Streamlit application
â”œâ”€â”€ main.py               # Alternative entry point
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ pyproject.toml       # Project configuration
â”œâ”€â”€ README.md            # This file
â”œâ”€â”€ .env                 # Environment variables (API keys)
â”œâ”€â”€ .streamlit/          # Streamlit configuration
â”œâ”€â”€ vector_store/        # ChromaDB persistent storage
â””â”€â”€ extracted_*.txt      # Auto-generated text files from PDFs
```

## ğŸ”‘ Configuration

### API Keys
The application requires a Google Gemini API key. You can obtain one from [Google AI Studio](https://makersuite.google.com/app/apikey).

### Models Used
- **Text Extraction**: `gemini-2.5-flash`
- **Chat Model**: `gemini-2.5-flash`
- **Embeddings**: `sentence-transformers/all-mpnet-base-v2`

### Vector Store Settings
- **Chunk Size**: 1000 characters
- **Chunk Overlap**: 200 characters
- **Top-K Retrieval**: 10 most similar chunks

